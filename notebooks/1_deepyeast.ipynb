{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deepyeast.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/totti0223/deep_learning_for_biologists_with_keras/blob/master/notebooks/1_deepyeast.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "qByeXeajxM3I",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Yeast GFP protein localization classification with CNN\n",
        "\n",
        "![yeast_image](https://github.com/totti0223/deep_learning_for_biologists_with_keras/raw/master/assets/yeast.jpg)\n",
        "Above image adopted from http://kodu.ut.ee/~leopoldp/2016_DeepYeast/\n",
        "\n",
        "##Reference\n",
        "*Accurate Classification of Protein Subcellular Localization from High-Throughput Microscopy Images Using Deep Learning\n",
        "Tanel Pärnamaa and Leopold Parts\n",
        "G3: GENES, GENOMES, GENETICS May 1, 2017 vol. 7 no. 5 1385-1392; https://doi.org/10.1534/g3.116.033654*\n",
        "\n",
        "http://kodu.ut.ee/~leopoldp/2016_DeepYeast/"
      ]
    },
    {
      "metadata": {
        "id": "lm2EGo6fEzMs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "cellView": "both",
        "id": "2e_pVLhVKAPS",
        "outputId": "754bfffb-70cc-4153-b072-16de4d0a2fd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "import os\n",
        "import math\n",
        "\n",
        "import itertools\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from skimage.exposure import equalize_adapthist\n",
        "\n",
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "\n",
        "import keras\n",
        "import keras.backend as K\n",
        "from keras.utils import np_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "\n",
        "from keras import layers,models\n",
        "from keras.models import Sequential\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "YzQa99cLlps5",
        "colab_type": "code",
        "outputId": "d2aad4f2-531e-4d4b-dcac-52c95c5ec1d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "cell_type": "code",
      "source": [
        "#update imagegenerator function\n",
        "!pip uninstall keras-preprocessing -y\n",
        "!pip install git+https://github.com/keras-team/keras-preprocessing.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling Keras-Preprocessing-1.0.5:\n",
            "  Successfully uninstalled Keras-Preprocessing-1.0.5\n",
            "Collecting git+https://github.com/keras-team/keras-preprocessing.git\n",
            "  Cloning https://github.com/keras-team/keras-preprocessing.git to /tmp/pip-req-build-h2wz77uy\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from Keras-Preprocessing==1.0.5) (1.14.6)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras-Preprocessing==1.0.5) (1.11.0)\n",
            "Building wheels for collected packages: Keras-Preprocessing\n",
            "  Running setup.py bdist_wheel for Keras-Preprocessing ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-kkep4d3b/wheels/03/a0/39/171f6040d36f36c71168dc69afa81334351b20955dc36ce932\n",
            "Successfully built Keras-Preprocessing\n",
            "Installing collected packages: Keras-Preprocessing\n",
            "Successfully installed Keras-Preprocessing-1.0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "skLWTfW3fIWa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras_preprocessing.image import ImageDataGenerator as _ImageDataGenerator\n",
        "#from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TFmnaSviDgzg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Prepare Data"
      ]
    },
    {
      "metadata": {
        "id": "K15DvQF-LD2-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Download yeast GFP datasets"
      ]
    },
    {
      "metadata": {
        "id": "kQiadj7aKELn",
        "colab_type": "code",
        "outputId": "2cf77d6f-0197-47bb-924b-7c016528a433",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "label_names = ['Cell_periphery','Cytoplasm','endosome','ER','Golgi','Mitochondrion','Nuclear_Periphery','Nucleolus','Nucleus','Peroxisome','Spindle_pole','Vacuole']\n",
        "\n",
        "\n",
        "def download_data():\n",
        "    print(\"Downloading dataset\")\n",
        "    paths = [\"main.tar.gz\",\"HOwt_train.txt\",\"HOwt_val.txt\",\"HOwt_test.txt\"]\n",
        "    data_path = get_file(paths[0],origin=\"http://kodu.ut.ee/~leopoldp/2016_DeepYeast/data/main.tar.gz\",extract=True,cache_subdir='deepyeast')\n",
        "    train_path = get_file(paths[1],origin=\"http://kodu.ut.ee/~leopoldp/2016_DeepYeast/code/reports/HOwt_train.txt\",cache_subdir='deepyeast')\n",
        "    val_path = get_file(paths[2],origin=\"http://kodu.ut.ee/~leopoldp/2016_DeepYeast/code/reports/HOwt_val.txt\",cache_subdir='deepyeast')\n",
        "    test_path = get_file(paths[3],origin=\"http://kodu.ut.ee/~leopoldp/2016_DeepYeast/code/reports/HOwt_test.txt\",cache_subdir='deepyeast')\n",
        "    return data_path,train_path,val_path,test_path\n",
        "\n",
        "def download_transfer_data():\n",
        "    print(\"Downloading dataset for transfer learning\")\n",
        "    paths = [\"transfer.tar.gz\",\"HOwt_transfer_train.txt\",\"HOwt_transfer_val.txt\",\"HOwt_transfer_test.txt\"]\n",
        "\n",
        "    data_path = get_file(paths[0], origin='http://kodu.ut.ee/~leopoldp/2016_DeepYeast/data/transfer.tar.gz',extract=True,cache_subdir='deepyeast_transfer')   \n",
        "    train_path = get_file(paths[1], origin='http://kodu.ut.ee/~leopoldp/2016_DeepYeast/code/image_prep/data/HOwt_transfer_train.txt', cache_subdir='deepyeast_transfer')\n",
        "    val_path = get_file(paths[2], origin='http://kodu.ut.ee/~leopoldp/2016_DeepYeast/code/image_prep/data/HOwt_transfer_val.txt', cache_subdir='deepyeast_transfer')\n",
        "    test_path = get_file(paths[3], origin='http://kodu.ut.ee/~leopoldp/2016_DeepYeast/code/image_prep/data/HOwt_transfer_test.txt', cache_subdir='deepyeast_transfer')\n",
        "\n",
        "data_path, train_path, val_path, test_path = download_data()\n",
        "\n",
        "print(data_path)\n",
        "print(train_path)\n",
        "print(val_path)\n",
        "print(test_path)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading dataset\n",
            "/root/.keras/deepyeast/main.tar.gz\n",
            "/root/.keras/deepyeast/HOwt_train.txt\n",
            "/root/.keras/deepyeast/HOwt_val.txt\n",
            "/root/.keras/deepyeast/HOwt_test.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iTS8r0qPFFVk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Read the CSV as pandas dataframe"
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "hSehOXkvxM3Q",
        "colab_type": "code",
        "outputId": "965c806b-f7d4-4c36-bcdd-55e9680e3978",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "parent_directory = \"/root/.keras/deepyeast/\"\n",
        "\n",
        "train_df = pd.read_csv(train_path,delimiter=\" \",names=(\"filename\",\"class\"),dtype={\"filename\":\"str\",\"class\":\"int\"})\n",
        "train_df[\"filename\"] = parent_directory + train_df[\"filename\"]\n",
        "\n",
        "valid_df = pd.read_csv(val_path,delimiter=\" \",names=(\"filename\",\"class\"),dtype={\"filename\":\"str\",\"class\":\"int\"})\n",
        "valid_df[\"filename\"] = parent_directory + valid_df[\"filename\"]\n",
        "\n",
        "test_df = pd.read_csv(test_path,delimiter=\" \",names=(\"filename\",\"class\"),dtype={\"filename\":\"str\",\"class\":\"int\"})\n",
        "test_df[\"filename\"] = parent_directory + test_df[\"filename\"]\n",
        "\n",
        "\n",
        "train_df[:5]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/root/.keras/deepyeast/plate10/015005000-6-151...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/root/.keras/deepyeast/plate01/007013000-2-626...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/root/.keras/deepyeast/plate01/003018000-2-262...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/root/.keras/deepyeast/plate10/004020000-0-141...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/root/.keras/deepyeast/plate08/006018000-0-113...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            filename  class\n",
              "0  /root/.keras/deepyeast/plate10/015005000-6-151...      0\n",
              "1  /root/.keras/deepyeast/plate01/007013000-2-626...      6\n",
              "2  /root/.keras/deepyeast/plate01/003018000-2-262...      1\n",
              "3  /root/.keras/deepyeast/plate10/004020000-0-141...      3\n",
              "4  /root/.keras/deepyeast/plate08/006018000-0-113...      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "CByrREkGmvgM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Create ImageDataGenerator Class"
      ]
    },
    {
      "metadata": {
        "id": "uGAlubbqTFUa",
        "colab_type": "code",
        "outputId": "acfb79ce-1dc5-46c3-bf94-925bfd8132f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "train_datagen = _ImageDataGenerator(rescale=1/255.)\n",
        "train_generator = train_datagen.flow_from_dataframe(dataframe=train_df,\n",
        "                                  directory=None,\n",
        "                                  x_col=\"filename\",\n",
        "                                  y_col=\"class\",\n",
        "                                  has_ext = True,\n",
        "                                  target_size=(64,64),\n",
        "                                  class_mode=\"categorical\")\n",
        "\n",
        "\n",
        "valid_datagen = _ImageDataGenerator(rescale=1/255.)\n",
        "valid_generator = valid_datagen.flow_from_dataframe(dataframe=valid_df,\n",
        "                                  directory=None,\n",
        "                                  x_col=\"filename\",\n",
        "                                  y_col=\"class\",\n",
        "                                  has_ext = True,\n",
        "                                  target_size=(64,64),\n",
        "                                  class_mode=\"categorical\")\n",
        "\n",
        "test_datagen = _ImageDataGenerator(rescale=1/255.)\n",
        "test_generator = test_datagen.flow_from_dataframe(dataframe=test_df,\n",
        "                                  directory=None,\n",
        "                                  x_col=\"filename\",\n",
        "                                  y_col=\"class\",\n",
        "                                  has_ext = True,\n",
        "                                  target_size=(64,64),\n",
        "                                  class_mode=\"categorical\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 65000 images belonging to 12 classes.\n",
            "Found 12500 images belonging to 12 classes.\n",
            "Found 12500 images belonging to 12 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4aUihkxNDmLz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Model preparation"
      ]
    },
    {
      "metadata": {
        "id": "-z2Cmw5EoA2P",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Create the CNN model"
      ]
    },
    {
      "metadata": {
        "id": "bxLi4ZsxoCtw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#basically follows the CNN network of the cited literature.\n",
        "\n",
        "model = Sequential([\n",
        "    #feature extraction layer\n",
        "    \n",
        "    #block1\n",
        "    layers.Conv2D(64,(3,3),padding=\"same\",name=\"block1_conv1\",input_shape=(64,64,3)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation(\"relu\"),\n",
        "    layers.Conv2D(64,(3,3),padding=\"same\",name=\"block1_conv2\"),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation(\"relu\"),\n",
        "    layers.MaxPooling2D((2,2),strides=(2,2),name=\"block1_pool\"),\n",
        "    #block2\n",
        "    layers.Conv2D(128,(3,3),padding=\"same\",name=\"block2_conv1\"),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation(\"relu\"),\n",
        "    layers.Conv2D(128,(3,3),padding=\"same\",name=\"block2_conv2\"),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation(\"relu\"),\n",
        "    layers.MaxPooling2D((2,2),strides=(2,2),name=\"block2_pool\"),\n",
        "    #block3\n",
        "    layers.Conv2D(256,(3,3),padding=\"same\",name=\"block3_conv1\"),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation(\"relu\"),\n",
        "    layers.Conv2D(256,(3,3),padding=\"same\",name=\"block3_conv2\"),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation(\"relu\"),\n",
        "    layers.Conv2D(256,(3,3),padding=\"same\",name=\"block3_conv3\"),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation(\"relu\"),\n",
        "    layers.Conv2D(256,(3,3),padding=\"same\",name=\"block3_conv4\"),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation(\"relu\"),\n",
        "    layers.MaxPooling2D((2,2),strides=(2,2),name=\"block3_pool\"),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    \n",
        "    #inference layer\n",
        "    layers.Dense(512,name=\"fc1\"),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation(\"relu\"),\n",
        "    layers.Dropout(0.5),\n",
        "    \n",
        "    layers.Dense(512,name=\"fc2\"),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation(\"relu\"),    \n",
        "    layers.Dropout(0.5),\n",
        "    \n",
        "    layers.Dense(12,name=\"prepredictions\"),\n",
        "    layers.Activation(\"softmax\",name=\"predictions\")\n",
        "    \n",
        "])\n",
        "\n",
        "model.compile(optimizer = \"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iXipZPRwEc0H",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##check the model architecture by model.summary"
      ]
    },
    {
      "metadata": {
        "id": "LJTyH-lLEXgs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1428
        },
        "outputId": "fe9d6ed4-7917-40ab-cee4-6ba9e638e8e1"
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "block1_conv1 (Conv2D)        (None, 64, 64, 64)        1792      \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 64, 64, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 64, 64, 64)        0         \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 64, 64, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 64, 64, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 64, 64, 64)        0         \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 32, 32, 128)       73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 32, 32, 128)       512       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 32, 32, 128)       147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 32, 32, 128)       512       \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 16, 16, 256)       295168    \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 16, 16, 256)       1024      \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 16, 16, 256)       590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 16, 16, 256)       1024      \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 16, 16, 256)       590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 16, 16, 256)       1024      \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv4 (Conv2D)        (None, 16, 16, 256)       590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 16, 16, 256)       1024      \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 16384)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 512)               8389120   \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "prepredictions (Dense)       (None, 12)                6156      \n",
            "_________________________________________________________________\n",
            "predictions (Activation)     (None, 12)                0         \n",
            "=================================================================\n",
            "Total params: 10,993,228\n",
            "Trainable params: 10,988,364\n",
            "Non-trainable params: 4,864\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Skl7e0-xr0pa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Train the CNN"
      ]
    },
    {
      "metadata": {
        "id": "fEWU5PSHr2y2",
        "colab_type": "code",
        "outputId": "57fbe13e-0237-463b-ce05-e905b174de90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1020
        }
      },
      "cell_type": "code",
      "source": [
        "#limiting the epochs to two. if you have time, change it to larger number and see how well it improves\n",
        "model.fit_generator(generator=train_generator,\n",
        "                    steps_per_epoch= train_generator.n//train_generator.batch_size,\n",
        "                    validation_data=valid_generator,\n",
        "                    validation_steps=valid_generator.n//valid_generator.batch_size,\n",
        "                    epochs=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "2031/2031 [==============================] - 262s 129ms/step - loss: 1.0030 - acc: 0.6667 - val_loss: 1.3184 - val_acc: 0.6189\n",
            "Epoch 2/2\n",
            "2031/2031 [==============================] - 257s 127ms/step - loss: 0.5191 - acc: 0.8307 - val_loss: 1.1925 - val_acc: 0.6370\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f204f591780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "HPT4kxYODXTz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load the pretrained model "
      ]
    },
    {
      "metadata": {
        "id": "BkgWk_cNDWc2",
        "colab_type": "code",
        "outputId": "f8c33d15-97f7-45fc-81a3-2d97e3cd19fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "#Lets download the pretrained model for people who cannot wait for the model to be sufficiently trained\n",
        "!wget https://raw.githubusercontent.com/totti0223/deep_learning_for_biologists_with_keras/master/notebooks/1_yeast_best_model.hdf5 -O 1_yeast_best_model.hdf5\n",
        "    \n",
        "#Load weights into the model\n",
        "model.load_weights(\"1_yeast_best_model.hdf5\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-12-24 07:16:21--  https://raw.githubusercontent.com/totti0223/deep_learning_for_biologists_with_keras/master/notebooks/1_yeast_best_model.hdf5\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 88055192 (84M) [application/octet-stream]\n",
            "Saving to: ‘1_yeast_best_model.hdf5’\n",
            "\n",
            "1_yeast_best_model. 100%[===================>]  83.98M   148MB/s    in 0.6s    \n",
            "\n",
            "2018-12-24 07:16:25 (148 MB/s) - ‘1_yeast_best_model.hdf5’ saved [88055192/88055192]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fA-VKjXlpsJx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Evaluate"
      ]
    },
    {
      "metadata": {
        "id": "BNlHbB3VkQJo",
        "colab_type": "code",
        "outputId": "64d0103e-5cc8-4092-b510-c1dc65891d34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "#lets see what kind of metrics can be obtained\n",
        "print(model.metrics_names) \n",
        "\n",
        "#evaluate train dataset, validation dataset, and test dataset\n",
        "\n",
        "print(\"train dataset: \", end = \"\")\n",
        "print(model.evaluate_generator(train_generator, steps = train_generator.n//train_generator.batch_size))\n",
        "\n",
        "print(\"validation dataset: \", end = \"\")\n",
        "print(model.evaluate_generator(valid_generator, steps = valid_generator.n//valid_generator.batch_size))\n",
        "\n",
        "print(\"test dataset: \", end = \"\")\n",
        "print(model.evaluate_generator(test_generator, steps = test_generator.n//test_generator.batch_size))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['loss', 'acc']\n",
            "train dataset: [0.10417130680581842, 0.9644748183721217]\n",
            "validation dataset: [0.4137479445156761, 0.8745192307692308]\n",
            "test dataset: [0.4667509896441912, 0.8633814102564102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Tuv8cg0kGeEk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "from the above evaluation, we can confirm that the classifier has 86.3% accuracy with 0.467 loss in the test dataset.\n",
        "more accuracy can be observed by modifying the CNN, training optimizer, and/or performing dataaugmentation in training dataset. try yourself!"
      ]
    },
    {
      "metadata": {
        "id": "i9O35wsGxM3m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "label_name = deepyeast.load_label_names() #label name that corresponds to the label number in dataset\n",
        "true_y = np.argmax(y_test,axis=1) #the true label of dataset\n",
        "pred_y = np.argmax(model.predict(X_test),axis=1) #predicted label of dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JpveukRGxM3n",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "evaluation summary function by sklearn."
      ]
    },
    {
      "metadata": {
        "id": "v3dnChioxM3n",
        "colab_type": "code",
        "outputId": "9a233b3a-a9e0-47bf-d928-4c3809e7635c",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(classification_report(true_y,pred_y,target_names=label_name))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                   precision    recall  f1-score   support\n",
            "\n",
            "   Cell_periphery       0.97      0.87      0.92      1569\n",
            "        Cytoplasm       0.84      0.92      0.88      1276\n",
            "         endosome       0.62      0.83      0.71       689\n",
            "               ER       0.89      0.92      0.91      1755\n",
            "            Golgi       0.92      0.82      0.87       382\n",
            "    Mitochondrion       0.89      0.90      0.90      1243\n",
            "Nuclear_Periphery       0.94      0.89      0.92      1164\n",
            "        Nucleolus       0.85      0.92      0.89      1263\n",
            "          Nucleus       0.95      0.82      0.88      1627\n",
            "       Peroxisome       0.53      0.81      0.64       164\n",
            "     Spindle_pole       0.81      0.57      0.67       781\n",
            "          Vacuole       0.74      0.88      0.80       587\n",
            "\n",
            "      avg / total       0.87      0.86      0.86     12500\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "esqxPh5wxM3p",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "let's get the confusion matrix, also using the sklearn function"
      ]
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "NYkh43A_xM3p",
        "colab_type": "code",
        "outputId": "6c3d9895-4f27-45d0-f853-a0ee6c9e9f8e",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import kwb.utils\n",
        "\n",
        "cnf = confusion_matrix(true_y, pred_y)\n",
        "np.set_printoptions(precision=2)\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "kwb.utils.plot_confusion_matrix(cnf, classes=label_name,\n",
        "                      title='Confusion matrix',normalize=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'confusion_matrix' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-acf26d42c903>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkwb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcnf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_printoptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'confusion_matrix' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "AV0XPknxxM3q",
        "colab_type": "code",
        "outputId": "aa0662eb-b31a-47c0-df88-4fbdbcee9f6f",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train, y_train, X_valid, y_valid,X_test,y_test = load_data(transfer=True)\n",
        "print(X_train.shape,y_train.shape,X_valid.shape,y_valid.shape,)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/home/dl-box/anaconda3/envs/keras/lib/python3.5/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
            "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(4000, 64, 64, 3) (4000, 4) (2000, 64, 64, 3) (2000, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jIRkcDctxM3s",
        "colab_type": "code",
        "outputId": "9e5fb88c-2969-4cf2-9d08-151e02d8c4a0",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#transfer learning with random forest.\n",
        "from keras.models import Model\n",
        "from keras import layers\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "for layer in model.layers:\n",
        "    layer.trainable = False    \n",
        "intlayer = model.get_layer(index=-2).output #get value before the last layer\n",
        "intmodel = Model(inputs=model.input,outputs=intlayer)\n",
        "\n",
        "int_X_train = intmodel.predict(X_train)\n",
        "int_X_test = intmodel.predict(X_test)\n",
        "print(int_X_train.shape,int_X_test.shape)\n",
        "\n",
        "clf = RandomForestClassifier(n_estimators=100, max_depth=2,random_state=0)\n",
        "clf.fit(int_X_train,np.argmax(y_train,axis=1))\n",
        "print(\"accuracy on train data:\", clf.score(int_X_train,np.argmax(y_train,axis=1)))\n",
        "print(\"accuracy on test data:\", clf.score(int_X_test,np.argmax(y_test,axis=1)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy on train data: 0.7155\n",
            "accuracy on test data: 0.61475\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "YCZQ9nqgxM3t",
        "colab_type": "code",
        "outputId": "d9a0dd95-2b0a-4b8a-d07f-51c8548743e4",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#another transfer learning that connects new dense layer to the learnt network\n",
        "import keras.backend as K\n",
        "\n",
        "K.clear_session()\n",
        "\n",
        "model =DeepYeast()\n",
        "model.load_weights(\"DeepYeast_Bestmodel.hdf5\")\n",
        "for layer in model.layers:\n",
        "    layer.trainable=False\n",
        "intlayer = model.get_layer(index=-2).output #get value before the last layer\n",
        "\n",
        "x = layers.Dense(4, activation='softmax', name='predictions')(intlayer)\n",
        "\n",
        "transfermodel = Model(inputs=model.input,outputs=x)\n",
        "transfermodel.summary() #note that trainable parameters are limited to dense layers only\n",
        "transfermodel.compile(\"sgd\",loss=\"categorical_crossentropy\",metrics=[\"acc\"])\n",
        "\n",
        "bestmodel = keras.callbacks.ModelCheckpoint(\"DeepYeast_Bestmodel_transfer.hdf5\",save_best_only=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 64, 64, 3)         0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 64, 64, 64)        1792      \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 64, 64, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 64, 64, 64)        0         \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 64, 64, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 64, 64, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 64, 64, 64)        0         \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 32, 32, 128)       73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 32, 32, 128)       512       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 32, 32, 128)       147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 32, 32, 128)       512       \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 16, 16, 256)       295168    \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 16, 16, 256)       1024      \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 16, 16, 256)       590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 16, 16, 256)       1024      \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 16, 16, 256)       590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 16, 16, 256)       1024      \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv4 (Conv2D)        (None, 16, 16, 256)       590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 16, 16, 256)       1024      \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 16384)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 512)               8389120   \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 4)                 2052      \n",
            "=================================================================\n",
            "Total params: 10,989,124\n",
            "Trainable params: 2,052\n",
            "Non-trainable params: 10,987,072\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "ImDe7-j7xM3u",
        "colab_type": "code",
        "outputId": "c8c7255e-473f-4a35-9925-ced08ed67e18",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "transfermodel.fit(X_train, y_train,\n",
        "                    epochs=50,batch_size = 100,callbacks=[bestmodel],\n",
        "                   validation_data=(X_valid,y_valid))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 4000 samples, validate on 2000 samples\n",
            "Epoch 1/50\n",
            "4000/4000 [==============================] - 2s 539us/step - loss: 1.5590 - acc: 0.4062 - val_loss: 1.2991 - val_acc: 0.4590\n",
            "Epoch 2/50\n",
            "4000/4000 [==============================] - 2s 429us/step - loss: 1.1935 - acc: 0.5527 - val_loss: 1.2290 - val_acc: 0.4830\n",
            "Epoch 3/50\n",
            "4000/4000 [==============================] - 2s 444us/step - loss: 1.1040 - acc: 0.5940 - val_loss: 1.1880 - val_acc: 0.5135\n",
            "Epoch 4/50\n",
            "4000/4000 [==============================] - 2s 431us/step - loss: 1.0418 - acc: 0.6100 - val_loss: 1.1516 - val_acc: 0.5360\n",
            "Epoch 5/50\n",
            "4000/4000 [==============================] - 2s 438us/step - loss: 1.0395 - acc: 0.6255 - val_loss: 1.1372 - val_acc: 0.5465\n",
            "Epoch 6/50\n",
            "4000/4000 [==============================] - 2s 440us/step - loss: 0.9982 - acc: 0.6468 - val_loss: 1.1202 - val_acc: 0.5505\n",
            "Epoch 7/50\n",
            "4000/4000 [==============================] - 2s 444us/step - loss: 0.9758 - acc: 0.6480 - val_loss: 1.1049 - val_acc: 0.5595\n",
            "Epoch 8/50\n",
            "4000/4000 [==============================] - 2s 428us/step - loss: 0.9872 - acc: 0.6477 - val_loss: 1.1022 - val_acc: 0.5680\n",
            "Epoch 9/50\n",
            "4000/4000 [==============================] - 2s 442us/step - loss: 0.9643 - acc: 0.6613 - val_loss: 1.1043 - val_acc: 0.5715\n",
            "Epoch 10/50\n",
            "4000/4000 [==============================] - 2s 443us/step - loss: 0.9480 - acc: 0.6755 - val_loss: 1.1071 - val_acc: 0.5645\n",
            "Epoch 11/50\n",
            "4000/4000 [==============================] - 2s 440us/step - loss: 0.9407 - acc: 0.6745 - val_loss: 1.0971 - val_acc: 0.5725\n",
            "Epoch 12/50\n",
            "4000/4000 [==============================] - 2s 435us/step - loss: 0.9318 - acc: 0.6745 - val_loss: 1.0939 - val_acc: 0.5830\n",
            "Epoch 13/50\n",
            "4000/4000 [==============================] - 2s 431us/step - loss: 0.9321 - acc: 0.6728 - val_loss: 1.1059 - val_acc: 0.5615\n",
            "Epoch 14/50\n",
            "4000/4000 [==============================] - 2s 437us/step - loss: 0.9195 - acc: 0.6773 - val_loss: 1.0973 - val_acc: 0.5760\n",
            "Epoch 15/50\n",
            "4000/4000 [==============================] - 2s 438us/step - loss: 0.9059 - acc: 0.6853 - val_loss: 1.0990 - val_acc: 0.5715\n",
            "Epoch 16/50\n",
            "4000/4000 [==============================] - 2s 443us/step - loss: 0.9041 - acc: 0.6810 - val_loss: 1.1052 - val_acc: 0.5670\n",
            "Epoch 17/50\n",
            "4000/4000 [==============================] - 2s 440us/step - loss: 0.8912 - acc: 0.6953 - val_loss: 1.1073 - val_acc: 0.5725\n",
            "Epoch 18/50\n",
            "4000/4000 [==============================] - 2s 445us/step - loss: 0.8962 - acc: 0.6902 - val_loss: 1.0999 - val_acc: 0.5780\n",
            "Epoch 19/50\n",
            "4000/4000 [==============================] - 2s 438us/step - loss: 0.8834 - acc: 0.6995 - val_loss: 1.0925 - val_acc: 0.5720\n",
            "Epoch 20/50\n",
            "4000/4000 [==============================] - 2s 425us/step - loss: 0.8838 - acc: 0.6960 - val_loss: 1.0983 - val_acc: 0.5685\n",
            "Epoch 21/50\n",
            "4000/4000 [==============================] - 2s 437us/step - loss: 0.8713 - acc: 0.7055 - val_loss: 1.1016 - val_acc: 0.5830\n",
            "Epoch 22/50\n",
            "4000/4000 [==============================] - 2s 440us/step - loss: 0.8709 - acc: 0.6913 - val_loss: 1.1018 - val_acc: 0.5705\n",
            "Epoch 23/50\n",
            "4000/4000 [==============================] - 2s 443us/step - loss: 0.8650 - acc: 0.7045 - val_loss: 1.1023 - val_acc: 0.5730\n",
            "Epoch 24/50\n",
            "4000/4000 [==============================] - 2s 443us/step - loss: 0.8671 - acc: 0.7085 - val_loss: 1.0975 - val_acc: 0.5845\n",
            "Epoch 25/50\n",
            "4000/4000 [==============================] - 2s 437us/step - loss: 0.8571 - acc: 0.7195 - val_loss: 1.1021 - val_acc: 0.5710\n",
            "Epoch 26/50\n",
            "4000/4000 [==============================] - 2s 440us/step - loss: 0.8581 - acc: 0.7100 - val_loss: 1.1110 - val_acc: 0.5660\n",
            "Epoch 27/50\n",
            "4000/4000 [==============================] - 2s 442us/step - loss: 0.8641 - acc: 0.7137 - val_loss: 1.1063 - val_acc: 0.5735\n",
            "Epoch 28/50\n",
            "4000/4000 [==============================] - 2s 444us/step - loss: 0.8526 - acc: 0.7168 - val_loss: 1.1042 - val_acc: 0.5715\n",
            "Epoch 29/50\n",
            "4000/4000 [==============================] - 2s 447us/step - loss: 0.8523 - acc: 0.7063 - val_loss: 1.1145 - val_acc: 0.5640\n",
            "Epoch 30/50\n",
            "4000/4000 [==============================] - 2s 446us/step - loss: 0.8457 - acc: 0.7155 - val_loss: 1.1123 - val_acc: 0.5660\n",
            "Epoch 31/50\n",
            "4000/4000 [==============================] - 2s 431us/step - loss: 0.8381 - acc: 0.7180 - val_loss: 1.0994 - val_acc: 0.5820\n",
            "Epoch 32/50\n",
            "4000/4000 [==============================] - 2s 447us/step - loss: 0.8412 - acc: 0.7235 - val_loss: 1.1058 - val_acc: 0.5715\n",
            "Epoch 33/50\n",
            "4000/4000 [==============================] - 2s 443us/step - loss: 0.8425 - acc: 0.7070 - val_loss: 1.0981 - val_acc: 0.5850\n",
            "Epoch 34/50\n",
            "4000/4000 [==============================] - 2s 442us/step - loss: 0.8318 - acc: 0.7137 - val_loss: 1.1009 - val_acc: 0.5800\n",
            "Epoch 35/50\n",
            "4000/4000 [==============================] - 2s 448us/step - loss: 0.8455 - acc: 0.7085 - val_loss: 1.1128 - val_acc: 0.5695\n",
            "Epoch 36/50\n",
            "4000/4000 [==============================] - 2s 442us/step - loss: 0.8303 - acc: 0.7140 - val_loss: 1.1035 - val_acc: 0.5830\n",
            "Epoch 37/50\n",
            "4000/4000 [==============================] - 2s 442us/step - loss: 0.8315 - acc: 0.7130 - val_loss: 1.1035 - val_acc: 0.5830\n",
            "Epoch 38/50\n",
            "4000/4000 [==============================] - 2s 444us/step - loss: 0.8360 - acc: 0.7118 - val_loss: 1.1039 - val_acc: 0.5835\n",
            "Epoch 39/50\n",
            "4000/4000 [==============================] - 2s 445us/step - loss: 0.8265 - acc: 0.7245 - val_loss: 1.1130 - val_acc: 0.5730\n",
            "Epoch 40/50\n",
            "4000/4000 [==============================] - 2s 446us/step - loss: 0.8282 - acc: 0.7135 - val_loss: 1.1198 - val_acc: 0.5575\n",
            "Epoch 41/50\n",
            "4000/4000 [==============================] - 2s 448us/step - loss: 0.8291 - acc: 0.7185 - val_loss: 1.1037 - val_acc: 0.5840\n",
            "Epoch 42/50\n",
            "4000/4000 [==============================] - 2s 442us/step - loss: 0.8255 - acc: 0.7190 - val_loss: 1.1013 - val_acc: 0.5855\n",
            "Epoch 43/50\n",
            "4000/4000 [==============================] - 2s 446us/step - loss: 0.8218 - acc: 0.7290 - val_loss: 1.1013 - val_acc: 0.5780\n",
            "Epoch 44/50\n",
            "4000/4000 [==============================] - 2s 444us/step - loss: 0.8156 - acc: 0.7278 - val_loss: 1.0995 - val_acc: 0.5880\n",
            "Epoch 45/50\n",
            "4000/4000 [==============================] - 2s 444us/step - loss: 0.8114 - acc: 0.7247 - val_loss: 1.1057 - val_acc: 0.5830\n",
            "Epoch 46/50\n",
            "4000/4000 [==============================] - 2s 443us/step - loss: 0.8262 - acc: 0.7195 - val_loss: 1.1091 - val_acc: 0.5740\n",
            "Epoch 47/50\n",
            "4000/4000 [==============================] - 2s 443us/step - loss: 0.8345 - acc: 0.7200 - val_loss: 1.1089 - val_acc: 0.5825\n",
            "Epoch 48/50\n",
            "4000/4000 [==============================] - 2s 443us/step - loss: 0.8223 - acc: 0.7240 - val_loss: 1.1135 - val_acc: 0.5645\n",
            "Epoch 49/50\n",
            "4000/4000 [==============================] - 2s 442us/step - loss: 0.8059 - acc: 0.7325 - val_loss: 1.1100 - val_acc: 0.5755\n",
            "Epoch 50/50\n",
            "4000/4000 [==============================] - 2s 427us/step - loss: 0.8127 - acc: 0.7235 - val_loss: 1.1150 - val_acc: 0.5710\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZEFubk__xM3w",
        "colab_type": "code",
        "outputId": "c33cc27c-9f74-447e-f888-c4bbfb9d5422",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(transfermodel.evaluate(X_train,y_train))\n",
        "print(transfermodel.evaluate(X_valid,y_valid))\n",
        "print(transfermodel.evaluate(X_test,y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4000/4000 [==============================] - 1s 362us/step\n",
            "[0.7705937781333924, 0.76175]\n",
            "2000/2000 [==============================] - 1s 365us/step\n",
            "[1.1149951038360595, 0.571]\n",
            "4000/4000 [==============================] - 1s 357us/step\n",
            "[0.9392598533630371, 0.669]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "reaURdRKxM3x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#with recent model\n",
        "K.clear_session()\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}